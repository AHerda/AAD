#import "template.typ": *

// Take a look at the file `template.typ` in the file panel
// to customize this template and discover how it works.
#show: project.with(
  title: [Algorytmiczna Analiza Danych\ Ä†wiczenia 2],
  //title: "Article\ntemplate\ntemplate 2",
  authors: (
    (name: "Adrian Herda", affiliation: "Informatyka Algorytmiczna, Politechnika WrocÅ‚awska"),
  ),
  date: datetime.today().display(),
)

= Zadanie 1
WyjaÅ›nij, czy dany scenariusz jest zwiÄ…zany z problemem klasyfikacji, czy regresji,
oraz wskaÅ¼, czy bardziej interesuje nas wnioskowanie (ang. inference), czy przewidywanie (ang. prediction).
Podaj rozmiar prÃ³by $n$ i liczbÄ™ predyktorÃ³w $p$

== Podpunkt a) wynagrodzenie prezesa a czynniki firmowe
*Typ problemu*: problem regresji - wynagrodzenie to zmienna ciÄ…gÅ‚a\
*Cel*: wnioskowanie - chcemy zrozumieÄ‡ zaleÅ¼noÅ›ci a nie przewidzieÄ‡ przyszÅ‚e zarobki prezesÃ³w\
*Rozmiar prÃ³by $n$*: 500 - liczba firm\
*Liczba predyktorÃ³w $p$*: 3 - zysk, liczba pracownikÃ³w, branÅ¼a - predyktory do dane ktÃ³re pozwalajÄ… na znalezienie korelacji

== Podpunkt b) wprowadzenie nowego produktu na rynek
*Typ problemu*: problem klasyfikacji - kategoryzujemy produkty na te ktÃ³re odniosÅ‚y sukces lub poraÅ¼kÄ™, sÄ… dwie klasy\
*Cel*: przewidywanie - chcemy przewidzieÄ‡ jak produkt poradzi sobie na rynku\
*Rozmiar prÃ³by $n$*: 20 - liczba podobnych produktÃ³w\
*Liczba predyktorÃ³w $p$*: 3 - cena, cena bezpoÅ›redniej konkurencji, budÅ¼et marketingowy

== Podpunkt c) prognozowanie zmian kursu dolara
*Typ problemu*: problem regresji - procentowe zmiany kursu to wartoÅ›Ä‡ liniowa\
*Cel*: przewidywanie - _"prognoza"_ to prÃ³ba przewidzenia danych w przyszÅ‚oÅ›ci\
*Rozmiar prÃ³by $n$*: 52 - liczba tygodni w roku\
*Liczba predyktorÃ³w $p$*: 4 - liczba porÃ³wnywanych rynkÃ³w akcji: USA, Wielka Brytania, Niemcy, Japonia

= Zadanie 2
Praktyczne zastosowania uczenia maszynowego: dla kaÅ¼dego z poniÅ¼szych punktÃ³w
zaproponuj dwa niesztampowe praktyczne zastosowania. Opisz jakie dane sÄ… potrzebne w wybranych
zastosowaniach, np. jakie cechy (ang. features) mogÄ… zostaÄ‡ uÅ¼yte jako predyktory, a jakie odpowiedzi,
czy potrzebna jest duÅ¼a liczba obserwacji.

== Klasyfikacja

=== PrzykÅ‚ad 1 - rozpoznawanie rodzajÃ³w wina
- Predykory:
  - gÄ™stoÅ›Ä‡ / lepkoÅ›Ä‡
  - zapach
  - kolor
  - smak
- Odpowiedzi
  - rodzaje wina

Potrzebna jest duÅ¼a iloÅ›Ä‡ obserwacji ze wzglÄ™du na iloÅ›Ä‡ rodzajÃ³w wina oraz ze wzglÄ™du na podobieÅ„stwo niektÃ³rych rodzajÃ³w.

=== PrzykÅ‚ad 2 - klasyfikacja emocji w rozmowach telefonicznych z klientami <p2>
- Predyktory:
  - ton mowy
  - tempo mowy
  - uÅ¼ywane wyraÅ¼enia
  - gÅ‚oÅ›noÅ›Ä‡
- Odpowiedzi
  - odpowiedzi na pytanie o zadowolenie z obsÅ‚ugi (bardzo pozytywne, pozytywne, neutralne, negatywne, bardzo negatywne)

Potrzebna jest duÅ¼a iloÅ›Ä‡ danych poniewaÅ¼ ludzkie emocje sÄ… bardzo skomplikowane i czÄ™sto niezrozumiaÅ‚e nawet dla nas samych. Nawet do setek tysiÄ™cy

== Regresja 

=== PrzykÅ‚ad 1 - Szacowanie wieku czÅ‚owieka na podstawie zdjÄ™cia (np takiego do ID)
- Predyktory:
  - kolor wÅ‚osÃ³w
  - zmarszczki
  - proporcje oczu do gÅ‚owy (szczegÃ³lnie u dzieci)
  - kolor skÃ³ry
  - przebarwienia
- Odpowiedzi:
  - wiek

Potrzebne moÅ¼e byÄ‡ nawet do dziesiÄ…tek tysiÄ™cy obserwacji moÅ¼e byÄ‡ potrzebne gdyÅ¼ fizjologia ludzka jest skomplikowana

=== PrzykÅ‚ad 2 - Prognozowanie czasu rozkÅ‚adu biodegradowalnych materiaÅ‚Ã³w
- Predyktory:
  - skÅ‚ad chemiczny
  - gÄ™stoÅ›Ä‡
  - porowatoÅ›Ä‡
  - temperatura
  - wilgotnoÅ›Ä‡
  - rodzaj Å›rodowiska (gleba, woda, kompost).
- OdpowiedÅº:
  - czas rozkÅ‚adu

Potrzebne bÄ™dÄ… setki eksperymentÃ³w laboratoryjnych i terenowych.

== Analiza klastrÃ³w

=== PrzykÅ‚ad 1 - Grupowanie utworÃ³w muzyczny wedÅ‚ug klas np. nastroju czy gatunku (np. Spotify)
- Predyktory:
  - tempo
  - tonacja
  - analiza tekstu - uÅ¼ywane sÅ‚owa i wyraÅ¼enia
  - gÅ‚oÅ›noÅ›Ä‡
  - uÅ¼yte instrumenty
  - uÅ¼yte narzÄ™dzia modyfikowania dÅºwiÄ™ku
- Odpowiedzi: brak klastrowanie odbywa siÄ™ bez nadzoru i tworzy wÅ‚asne klasy / etykiety.
- PrzykÅ‚adowe etykiety nadane przez algorytm: muzyka melancholijna, wesoÅ‚a, skoczna, buntownicza

Setki tysiÄ™cy lub nawet miliony utworÃ³w bÄ™dÄ… potrzebne by znaleÅºÄ‡ widocznie wyrÃ³Å¼niajÄ…ce siÄ™ klastry.

=== PrzykÅ‚ad 2 - PodziaÅ‚ klientÃ³w sklepu na grupy o podobnych zainteresowaniach
- Predyktory:
  - Å›rednia wartoÅ›Ä‡ zakupÃ³w
  - czÄ™stotliwoÅ›Ä‡ zakupÃ³w
  - najczÄ™Å›ciej kupowane i przeglÄ…dane oferty
  - ocena satysfakcji klienta
  - lokalizacja klienta (moÅ¼e byÄ‡ nie dokÅ‚adna, np. region - ciepÅ‚y czy zimny)
- Odpowiedzi: brak klastrowanie odbywa siÄ™ bez nadzoru i tworzy wÅ‚asne klasy / etykiety.
- PrzykÅ‚adowe etykiety nadane przez algorytm: klient zainteresowany ciuchami zimowymi / letnimi, wÄ™dkarz, sportowiec, kolekcjoner butÃ³w, staÅ‚y klient, klient jednorazowy

Setki tysiÄ™cy klientÃ³w bÄ™dÄ… potrzebne by znaleÅºÄ‡ wyrÃ³Å¼niajÄ…ce siÄ™ klastry.

= Zadanie 3 - uczenie statystyczne - parametryczne a nieparametryczne

Opisz rÃ³Å¼nice miÄ™dzy parametrycznym a nieparametrycznym podejÅ›ciem do uczenia statystycznego. Jakie sÄ… wady i zalety podejÅ›cia parametrycznego w porÃ³wnaniu do podejÅ›cia nieparametrycznego?

== Parametryczne

ZakÅ‚ada pewien rozkÅ‚ad danych, za pomocÄ… skoÅ„czonej (nie ogromnej) iloÅ›ci parametrÃ³w. UmoÅ¼liwia stosunkowo Å‚atwÄ… analizÄ™ modelu ale sprawia Å¼e jest ona tylko przybliÅ¼eniem. To podejÅ›cie jest teÅ¼ mniej elastyczne i jest podatne na bÅ‚Ä™dy zwiÄ…zane z biasem.

== Nieparametryczna

Nie wymaga zaÅ‚oÅ¼eÅ„ co do rozkÅ‚adu danych . Model uczy siÄ™ bardziej elastycznie dopasowujÄ…c siÄ™ do obserwacji. DziÄ™ki temu otrzymujemy mniejszy bias ale moÅ¼liwym jest zbytnio dopasowaÄ‡ model do danych (ang. overfitting). PodejÅ›cie to wymaga duÅ¼ej liczby obserwacji i przez to jest bardziej kosztowne niÅ¼ podejÅ›cie parametryczne.

#pagebreak()
== Zalety i wady

#table(columns: (auto, 1fr, 1fr),
  table.header([], [Uczenie parametryczne], [Uczenie nieparamteryczne]),
  [Zalety], 
  [
    - maÅ‚y wariancja
    - Å‚atwoÅ›Ä‡ analizy i interpretacji modelu
    - niski koszt obliczeÅ„
  ], 
  [
    - maÅ‚y bias
    - duÅ¼a elastycznoÅ›Ä‡ i dopasowanie do danych
    - Nie wymaga zaÅ‚oÅ¼eÅ„ o danych
  ],
  [Wady],
  [
    - duÅ¼y bias
    - maÅ‚a elastycznoÅ›Ä‡
    - sÅ‚aba moc predykcyjna
    - wymaga zaÅ‚oÅ¼eÅ„ o danych
  ],
  [
    - duÅ¼a wariancja
    - niezrozumiaÅ‚y sposÃ³b dziaÅ‚ania (black box)
    - duÅ¼y koszt obliczeÅ„
  ],
)

= Zadanie 4 - zbiÃ³r treningowy dla metody $K$ najbliÅ¼szych sÄ…siadÃ³w (ang. $K$-nearest neighbors)

== a) odlegÅ‚oÅ›Ä‡ euklidesowa dla kaÅ¼dego punktu
+ $sqrt(0^2 + 3^2 + 0^2) = sqrt(9) = 3$,
+ $sqrt(2^2 + 0^2 + 0^2) = sqrt(4) = 2$,
+ $sqrt(0^2 + 1^2 + 3^2) = sqrt(10)$,
+ $sqrt(0^2 + 1^2 + 2^2) = sqrt(5)$,
+ $sqrt((-1)^2 + 0^2 + 1^2) = sqrt(2)$,
+ $sqrt(1^2 + 1^2 + 1^2) = sqrt(3)$

== b) predykcja dla $K = 1$

Bierzemy najbliÅ¼szego sÄ…siada ktÃ³rym jest obserwacja $5$ i bierzemy jego odpowiedÅº #sym.arrow #text(green)[*_Green_*]

== c) predykcja dla $K = 3$

Bierzemy $3$ najbliÅ¼szych sÄ…siadÃ³w ktÃ³rymi sÄ… obserwacje $5 -> "Green"$, $6 -> "Red"$ oraz $2 -> "Red"$ i bierzemy najpopularniejszÄ… odpowiedÅº wÅ›rÃ³d tych obserwacji #sym.arrow #text(red)[*_Red_*]

== d) lepsze maÅ‚e czy duÅ¼e wartoÅ›ci $K$ dla silnie nieliniowej granicy decyzyjnej Bayesa
JeÅ›li granica decyzyjna Bayesa jest silnie nieliniowa (czyli prawdziwa granica miÄ™dzy klasami jest bardzo zÅ‚oÅ¼ona), to potrzebujemy bardziej elastycznego modelu, aby tÄ™ zÅ‚oÅ¼onoÅ›Ä‡ uchwyciÄ‡. MaÅ‚e wartoÅ›ci $ğ¾$ dajÄ… klasyfikatorowi _KNN_ wiÄ™kszÄ… elastycznoÅ›Ä‡ (niÅ¼szy bias, wyÅ¼sza wariancja) i pozwalajÄ… na odwzorowanie skomplikowanych, lokalnych zaleÅ¼noÅ›ci. Dlatego przy silnie nieliniowej granicy Bayesa zwykle lepiej sprawdzÄ… siÄ™ maÅ‚e wartoÅ›ci $ğ¾$. (Przy przeciwnym zaÅ‚oÅ¼eniu â€” gÅ‚adkiej granicy â€” wiÄ™ksze $K$ redukuje wariancjÄ™ i moÅ¼e daÄ‡ lepsze wyniki).

= Zadanie 5 - WartoÅ›Ä‡ oczekiwana i wariancja sumy zmiennych losowych

$ "Cov"(X, Y) = 0 $<eq1>

== a) $EE(X + Y) = EE(X) + EE(Y)$
#proof[$
  EE(X + Y) &= sum_x sum_y (x + y)Pr(X = x, Y = y)\
  &= sum_x sum_y x dot Pr(X = x, Y = y) + sum_x sum_y y dot Pr(X = x, Y = y)\
  &= sum_x x dot (sum_y dot Pr(X = x, Y = y)) + sum_y y dot (sum_x dot Pr(X = x, Y = y))\
  &= sum_x x dot Pr(X = x) + sum_y y dot Pr(Y = y)\
  &= EE(X) + EE(Y)
$]

== b) $"Var"(X + Y) = "Var"(X) + "Var"(Y)$
#proof[$
  "Var"(X) = EE[(X - EE(X))^2] and (1)\ arrow.b.double $$
  "Var"(X + Y) &= EE[(X + Y - EE(X + Y))^2] \
  &= EE[((X - EE(X)) + (Y - EE(Y)))^2]\
  &= EE[(X - EE(X))^2 + (Y - EE(Y))^2 + 2 dot (X - EE(X)) dot (Y - EE(Y))]\
  &= EE[(X - EE(X))^2] + EE[(Y - EE(Y))^2] + EE[2 dot (X - EE(X)) dot (Y - EE(Y))]\
  &= "Var"(X) + "Var"(Y) + underbrace(2 dot "Cov"(X, Y), 0)\
  &= "Var"(X) + "Var"(Y)
$]

= Zadanie 6 - Przypomnienie estymatrÃ³w, jego bias'u i wariancji wrac z przykÅ‚adami

Przypomnij, co to jest estymator oraz co to jest obciÄ…Å¼enie (ang. bias) i wariancja
estymatora. Podaj przykÅ‚ady estymatorÃ³w obciÄ…Å¼onych i nieobciÄ…Å¼onych

== Definicje

/ Estymator: To funkcja majÄ…ca za zadanie przybliÅ¼yÄ‡ (wyestymowaÄ‡) wybrany parametr. $ theta approx hat(theta)(X_1, X_2, dots.c, X_n) $
/ Bias estymatora: Jest wartoÅ›Ä‡ opisujÄ…ca tendencje estymatora do zawyÅ¼ania lub zaniÅ¼ania wartoÅ›ci estymowanej $ "Bias"(hat(theta)) = EE(hat(theta)) - theta $
  - Estymator nazywamy obciÄ…Å¼onym gdy $"Bias"(hat(theta)) != 0$
  - Estymator nazywamy nieobciÄ…Å¼onym gdy $"Bias"(hat(theta)) = 0 => EE(hat(theta)) = theta$
/ Wariancja estymatora: sÅ‚uÅ¼y ocenianiu jak daleko, zazwyczaj, bÄ™dzie estymator od estymowanej wartoÅ›ci $ "Var"(hat(theta)) = EE((EE(hat(theta)) - hat(theta))^2) $
/ MSE: Mean Square Error (ang. BÅ‚Ä…d Å›redniokwadratowy) tak samo jak wariancja $ "MSE"(hat(theta)) = EE((hat(theta)(X) - theta)^2) $

== PrzykÅ‚ady

=== NieobciÄ…Å¼ony

#table(
  columns: (auto, 1fr, 1fr),
  table.header([Typ estymatora], [PrzykÅ‚ad], [ObciÄ…Å¼enie]),
  [Åšrednia z prÃ³by], [$hat(mu) = 1/n sum_(i=1)^n X_i$], [$EE(hat(mu)) = mu => "Bias"(hat(mu)) = 0$],
  [Wariancja z $n - 1$], [$hat(sigma)_(n - 1)^2 = 1/ (n-1) sum_(i=1)^n (X_i - dash(X))^2$], [$EE(hat(sigma)_(n-1)^2) = sigma^2 => "Bias"(hat(sigma)_(n-1)^2) = 0$],
)

=== ObciÄ…Å¼ony

#table(
  columns: (auto, 1fr, 1fr),
  table.header([Typ estymatora], [PrzykÅ‚ad], [ObciÄ…Å¼enie]),
  [Wariancja z $n$], [$hat(sigma)_n^2 = 1/ n sum_(i=1)^n (X_i - dash(X))^2$], [$EE(hat(sigma)_n^2) = (n-1)/n sigma^2 => "Bias"(hat(sigma)_n^2) = -sigma^2 / n$],
  [$X tilde "Exp"(lambda)$], [MLE $hat(lambda)=1/dash(X)$], [$EE(hat(lambda)) = n / (n-1) => "Bias"(hat(lambda)) = 1/(n-1) lambda$]
)

= Zadanie 7 - dopasowywanie elastycznoÅ›ci modelu do scenariusza

Szukamy odpowiedniego modelu dla problemu zwiÄ…zanego z uczeniem nadzorowanym. Dla kaÅ¼dego z punktÃ³w od (a) do (d), wskaÅ¼, czy ogÃ³lnie oczekiwalibyÅ›my, Å¼e maÅ‚o â€elastycznyâ€ model bÄ™dzie lepszy czy gorsza od bardziej â€elastycznegoâ€. Uzasadnij swojÄ… odpowiedÅº.\
  #h(1em) (a) Rozmiar prÃ³by $n$ jest bardzo duÅ¼y, a liczba predyktorÃ³w (and. predictor) $p$ jest maÅ‚a.\
  #h(1em) (b) Liczba predyktorÃ³w $p$ jest bardzo duÅ¼a, a liczba obserwacji $n$ jest maÅ‚a.\
  #h(1em) (c) ZaleÅ¼noÅ›Ä‡ miÄ™dzy predyktorami a odpowiedziÄ… (and. response) wykazuje wyraÅºnie nieliniowy charakter.\
  #h(1em) (d) Wariancja bÅ‚Ä™dÃ³w, tj. $sigma^2 = VV"ar"(epsilon)$, jest bardzo wysoka.\

SformuÅ‚uj wnioski dotyczÄ…ce tego, jakie sÄ… zalety i wady bardziej elastycznego modelu, w porÃ³wnaniu z
mniej elastycznym? W jakich okolicznoÅ›ciach bardziej elastyczny model moÅ¼e byÄ‡ preferowany? Kiedy
preferowany moÅ¼e byÄ‡ mniej elastyczny model?

#table(
  columns: (auto, auto, 1fr),
  table.header([Przypadek], [ElastycznoÅ›Ä‡ modelu], [Uzasadnienie]),
  [a) $n$ - duÅ¼e,\ $p$ - maÅ‚e], [Bardziej elastyczny], [Elastyczny model moÅ¼e wykorzystaÄ‡ duÅ¼Ä… liczbÄ™ obserwacji aby dopasowaÄ‡ siÄ™ i dziÄ™ki temu obniÅ¼a bias],
  [b) $n$ - maÅ‚e\ $p$ - duÅ¼e], [Mniej elastyczny], [DuÅ¼a liczba predyktorÃ³w grozi overfittingiem, naleÅ¼y najpierw dokonaÄ‡ redukcji wymiaru tak aby $p$ byÅ‚o mniejsze od  $n$ a nastÄ™pnie wykorzystaÄ‡ mniej elastyczny model aby uzyskaÄ‡ model zwiÄ™kszyÄ‡ wydajnoÅ›Ä‡ na maÅ‚ej iloÅ›ci danych] ,
  [c) silna nieliniowoÅ›Ä‡ danych], [Bardziej elastyczny], [Elastyczny model lepiej dopasuje siÄ™ do danych i lepiej przedstawi nieliniowoÅ›Ä‡, nie uÅ›redniajÄ…c jej tak jak zrobiÅ‚by to model mniej elastyczny],
  [d) Wysoka wariancja szumu], [Mniej elastyczny], [Mniej elastyczny model uÅ›redni dane i zniweluje w ten sposÃ³b wysokÄ… wariancjÄ™ szumu]
)

== Wnioski

#table(columns: (auto, 1fr, 1fr),
  table.header([], [Model mniej elastyczny], [Model bardziej elastyczny]),
  [Zalety], 
  [
    - stabilny, z maÅ‚a wariancjÄ…
    - Å‚atwiejszy do interpretacji
    - bardziej odporny na szum
    - sprawdza siÄ™ lepiej dla maÅ‚ych $n$ wzglÄ™dem $p$
  ], 
  [
    - niski bias
    - Å›wietny dla duÅ¼ych $n$
    - uchwyci zÅ‚oÅ¼one zaleÅ¼noÅ›ci
  ],
  [Wady],
  [
    - duÅ¼y bias
    - sÅ‚aby przy duÅ¼ej nieliniowoÅ›ci danych
  ],
  [
    - duÅ¼a wariancja
    - niezrozumiaÅ‚y sposÃ³b dziaÅ‚ania (black box)
    - duÅ¼y koszt obliczeÅ„
    - kiepski dla maÅ‚ych $n$
    - ryzyko overfittingu
  ],
)